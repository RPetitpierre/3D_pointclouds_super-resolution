{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pytorch to train (almost) the same CNN as in the demo for digit recognition (the only difference being that we have 28x28 images instead of 32x32 ones). \n",
    "\n",
    "Let us load and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist_data', train=True,\n",
    "                                      download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./mnist_data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c23518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now define a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1,16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the cross-entropy loss and SGD with momentum to optimize the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.224\n",
      "[1,  4000] loss: 0.250\n",
      "[1,  6000] loss: 0.161\n",
      "[1,  8000] loss: 0.126\n",
      "[1, 10000] loss: 0.106\n",
      "[1, 12000] loss: 0.091\n",
      "[1, 14000] loss: 0.086\n",
      "[2,  2000] loss: 0.062\n",
      "[2,  4000] loss: 0.058\n",
      "[2,  6000] loss: 0.063\n",
      "[2,  8000] loss: 0.066\n",
      "[2, 10000] loss: 0.056\n",
      "[2, 12000] loss: 0.058\n",
      "[2, 14000] loss: 0.054\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # clear the gradients of the variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 98 %\n",
      "Accuracy of     1 : 99 %\n",
      "Accuracy of     2 : 98 %\n",
      "Accuracy of     3 : 97 %\n",
      "Accuracy of     4 : 98 %\n",
      "Accuracy of     5 : 98 %\n",
      "Accuracy of     6 : 99 %\n",
      "Accuracy of     7 : 99 %\n",
      "Accuracy of     8 : 98 %\n",
      "Accuracy of     9 : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
