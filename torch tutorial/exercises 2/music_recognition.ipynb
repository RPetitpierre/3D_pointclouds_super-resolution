{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music genre recognition from images\n",
    "\n",
    "We will compare the performance of logistic regression and MLP on the task of music genre recognition. \n",
    "\n",
    "We will use the small FMA (Free Music Archive) dataset of Defferrard et al., FMA: A Dataset For Music Analysis, ISMIR 2017. This dataset consists of 8000 balanced samples (30 sec each) from 8 different genres (International, Pop, Rock, Electronic, Folk, Hip-Hop, Experimental, Instrumental). The data contains:\n",
    "- X: standard features of each sample (provided by the authors)\n",
    "- Y: the label of each sample\n",
    "\n",
    "Let us first load the data. To make use of the pytorch dataloader, we will create a new Dataset class. This class needs to have functions to create a new instance of the class, get the number of samples in a dataset and get one data sample. As in the MNIST case, we will make use of a boolean variable to indicate whether this dataset contains training data or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio # This will allow us to load the data\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mat_file, train, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mat_file (string): Path to the mat file with the data\n",
    "            train (boolean): Is it the training data or the test data\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        data = sio.loadmat(mat_file)\n",
    "        self.X = data['X']\n",
    "        self.Y = data['Y'].squeeze()\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(self.X,self.Y,test_size=0.25,random_state=1)\n",
    "        Xtrain = preprocessing.scale(Xtrain)\n",
    "        Xtest = preprocessing.scale(Xtest)\n",
    "        self.Xtrain = Xtrain.astype(float)\n",
    "        self.Xtest = Xtest.astype(float)\n",
    "        self.Ytrain = Ytrain.astype(float)\n",
    "        self.Ytest = Ytest.astype(float)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return (self.Xtrain.shape[0])\n",
    "        else:\n",
    "            return (self.Xtest.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.train:\n",
    "            sample = {'features': self.Xtrain[idx,:], 'label': self.Ytrain[idx]}\n",
    "        else:\n",
    "            sample = {'features': self.Xtest[idx,:], 'label': self.Ytest[idx]}\n",
    "            \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "As a baseline, we will make use of a logistic regression classifier.\n",
    "\n",
    "Let us first create the corresponding training and test sets using our new class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MusicDataset(mat_file='music_data.mat', train=True)\n",
    "testset = MusicDataset(mat_file='music_data.mat', train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=1,tol=0.001)\n",
    "clf.fit(trainset.Xtrain,trainset.Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat = clf.predict(testset.Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  11,  13,   9,  29,  20,  11,  14],\n",
       "       [ 22,  81,  34,  23,  25,  21,  22,  16],\n",
       "       [  7,  21, 181,  13,  11,   5,  20,  12],\n",
       "       [ 11,  13,   4, 142,   1,  27,  16,  25],\n",
       "       [ 15,  24,  15,   5, 140,   4,  19,  29],\n",
       "       [ 14,  19,   4,  35,   4, 165,  15,   6],\n",
       "       [ 11,  21,  16,  14,  25,  12, 100,  41],\n",
       "       [  2,  10,   6,  13,  19,   2,  28, 135]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "cmat = skm.confusion_matrix(testset.Ytest, Yhat)\n",
    "cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(cmat).sum()/cmat.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron\n",
    "\n",
    "Let us now move to the MLP.\n",
    "\n",
    "To use pytorch, we will need to convert the data to tensors. This can be achieved by creating a new transform as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        features, label = sample['features'], sample['label']\n",
    "\n",
    "        return {'features': torch.from_numpy(features).float(),\n",
    "                'label': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the training and test set, and directly apply our new transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MusicDataset(mat_file='music_data.mat', train=True, transform=ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = MusicDataset(mat_file='music_data.mat', train=False, transform=ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new MLP. Test different architectures. (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the tutorial, we will make use of the cross-entropy as a loss and of SGD with momentum as an optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now train your model. Try different number of epochs. To obtain the inputs, you can use \"features = data['features']\" and for the labels \"labels = data['label'].long()\". (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 1.774\n",
      "[1,  1000] loss: 1.729\n",
      "[1,  1500] loss: 1.685\n",
      "[2,   500] loss: 1.643\n",
      "[2,  1000] loss: 1.566\n",
      "[2,  1500] loss: 1.562\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test data (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
